train_dual: weights=yolov9-c.pt, cfg=models/detect/yolov9-c.yaml, data=data.yaml, hyp=hyp.scratch-high.yaml, epochs=100, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=C:/Mansura/UTI/Version-Final/YOLOv9-c, name=training.1, exist_ok=True, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest
YOLO  v0.1-104-g5b1ea9a Python-3.11.5 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3
ClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLO  in ClearML
Comet: run 'pip install comet_ml' to automatically track and visualize YOLO  runs in Comet
TensorBoard: Start with 'tensorboard --logdir C:\Mansura\UTI\Version-Final\YOLOv9-c', view at http://localhost:6006/
Overriding model.yaml nc=80 with nc=7

                 from  n    params  module                                  arguments                     
  0                -1  1         0  models.common.Silence                   []                            
  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 
  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        
  4                -1  1    164352  models.common.ADown                     [256, 256]                    
  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       
  6                -1  1    656384  models.common.ADown                     [512, 512]                    
  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       
  8                -1  1    656384  models.common.ADown                     [512, 512]                    
  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       
 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 7]  1         0  models.common.Concat                    [1]                           
 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      
 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 15           [-1, 5]  1         0  models.common.Concat                    [1]                           
 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      
 17                -1  1    164352  models.common.ADown                     [256, 256]                    
 18          [-1, 13]  1         0  models.common.Concat                    [1]                           
 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       
 20                -1  1    656384  models.common.ADown                     [512, 512]                    
 21          [-1, 10]  1         0  models.common.Concat                    [1]                           
 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      
 23                 5  1    131328  models.common.CBLinear                  [512, [256]]                  
 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]             
 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]        
 26                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 
 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        
 29                -1  1    164352  models.common.ADown                     [256, 256]                    
 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   
 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       
 32                -1  1    656384  models.common.ADown                     [512, 512]                    
 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      
 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       
 35                -1  1    656384  models.common.ADown                     [512, 512]                    
 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         
 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       
 38[31, 34, 37, 16, 19, 22]  1  21556682  models.yolo.DualDDetect                 [7, [512, 512, 512, 256, 512, 512]]
yolov9-c summary: 962 layers, 51013450 parameters, 51013418 gradients, 238.9 GFLOPs

Transferred 1448/1460 items from yolov9-c.pt
AMP: checks passed 
optimizer: SGD(lr=0.01) with parameter groups 238 weight(decay=0.0), 255 weight(decay=0.0005), 253 bias
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))
train: Scanning C:\Mansura\UTI\data\DATA-UTI-LR\Data\train\labels... 4256 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4256/4256 00:09
train: WARNING  Cache directory C:\Mansura\UTI\data\DATA-UTI-LR\Data\train is not writeable: [WinError 183] Cannot create a file when that file already exists: 'C:\\Mansura\\UTI\\data\\DATA-UTI-LR\\Data\\train\\labels.cache.npy' -> 'C:\\Mansura\\UTI\\data\\DATA-UTI-LR\\Data\\train\\labels.cache'
val: Scanning C:\Mansura\UTI\data\DATA-UTI-LR\Data\val\labels... 268 images, 0 backgrounds, 0 corrupt: 100%|██████████| 268/268 00:06
val: WARNING  Cache directory C:\Mansura\UTI\data\DATA-UTI-LR\Data\val is not writeable: [WinError 183] Cannot create a file when that file already exists: 'C:\\Mansura\\UTI\\data\\DATA-UTI-LR\\Data\\val\\labels.cache.npy' -> 'C:\\Mansura\\UTI\\data\\DATA-UTI-LR\\Data\\val\\labels.cache'
Plotting labels to C:\Mansura\UTI\Version-Final\YOLOv9-c\training.1\labels.jpg... 
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to C:\Mansura\UTI\Version-Final\YOLOv9-c\training.1
Starting training for 100 epochs...

AttributeError: 'FreeTypeFont' object has no attribute 'getsize'
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:03
                   all        268       1692      0.863      0.843      0.916      0.606
                  cast        268        194      0.772      0.732      0.838      0.513
                 cryst        268         84       0.94       0.75      0.943      0.677
                 epith        268        418      0.868      0.904      0.944      0.672
                epithn        268         35       0.76      0.743      0.809      0.406
                 eryth        268        599      0.953      0.955      0.981      0.675
                 leuko        268        261      0.836      0.908      0.931      0.621
                mycete        268        101      0.911      0.907       0.97      0.674
Results saved to C:\Mansura\UTI\Version-Final\YOLOv9-c\training.1