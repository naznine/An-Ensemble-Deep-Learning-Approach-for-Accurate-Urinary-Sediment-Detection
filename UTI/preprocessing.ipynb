{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7047,"status":"ok","timestamp":1713436561429,"user":{"displayName":"Mohammad Chowdhury","userId":"00677925176328149573"},"user_tz":-360},"id":"DoZMQGtczDMc"},"outputs":[],"source":["import os\n","import pathlib\n","import shutil\n","import json\n","import yaml\n","import locale\n","import argparse\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","locale.getpreferredencoding = lambda: \"UTF-8\""]},{"cell_type":"markdown","metadata":{},"source":["Make subset data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import random\n","import shutil\n","\n","def create_subset(images_dir, labels_dir, output_images_dir, output_labels_dir, sample_size):\n","    if not os.path.exists(output_images_dir):\n","        os.makedirs(output_images_dir)\n","    if not os.path.exists(output_labels_dir):\n","        os.makedirs(output_labels_dir)\n","    \n","    files = os.listdir(images_dir)\n","    random.shuffle(files)\n","    \n","    sample_files = files[:sample_size]\n","    \n","    for file_name in sample_files:\n","        image_path = os.path.join(images_dir, file_name)\n","        label_path = os.path.join(labels_dir, os.path.splitext(file_name)[0] + '.txt')  # Assuming label files have the same name with .txt extension\n","        \n","        output_image_path = os.path.join(output_images_dir, file_name)\n","        output_label_path = os.path.join(output_labels_dir, os.path.splitext(file_name)[0] + '.txt')\n","        \n","        shutil.copy(image_path, output_image_path)\n","        shutil.copy(label_path, output_label_path)\n","\n","def create_subset_for_all(base_input_dir, base_output_dir, train_size, val_size, test_size):\n","    sets = [\n","        ('train', train_size),\n","        ('val', val_size),\n","        ('test', test_size)\n","    ]\n","    \n","    for set_name, size in sets:\n","        images_dir = os.path.join(base_input_dir, set_name, 'images')\n","        labels_dir = os.path.join(base_input_dir, set_name, 'labels')\n","        \n","        output_images_dir = os.path.join(base_output_dir, set_name, 'images')\n","        output_labels_dir = os.path.join(base_output_dir, set_name, 'labels')\n","        \n","        create_subset(images_dir, labels_dir, output_images_dir, output_labels_dir, size)\n","\n","# Define the base directories for the input and output datasets\n","base_input_dir = r\"C:/Mansura/UTI/data/DATA-UTI-LR/Data\"\n","base_output_dir = r\"C:/Mansura/UTI/data/DATA-UTI-LR/Sample-Data\"\n","\n","# Define the sample sizes for each set\n","train_sample_size = 500\n","val_sample_size = 100\n","test_sample_size = 200\n","\n","# Create subsets of the dataset\n","create_subset_for_all(base_input_dir, base_output_dir, train_sample_size, val_sample_size, test_sample_size)\n"]},{"cell_type":"markdown","metadata":{},"source":["CLAHE and GAMMA Correction"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","def clahe_function(img):\n","    # Create CLAHE object\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n","\n","    # Convert BGR image to LAB color space\n","    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","    # Split LAB image into channels\n","    lab_planes = list(cv2.split(lab_img))\n","\n","    # Apply CLAHE to the L channel\n","    clahe_img = clahe.apply(lab_planes[0])\n","\n","    # Merge the CLAHE-enhanced L channel with the original A and B channels\n","    lab_planes[0] = clahe_img\n","    updated_lab_img = cv2.merge(lab_planes)\n","\n","    # Convert LAB image back to BGR color space\n","    clahe_img_bgr = cv2.cvtColor(updated_lab_img, cv2.COLOR_LAB2BGR)\n","\n","    return clahe_img_bgr\n","\n","def gamma_correction(img, gamma=1.5):\n","    # Apply gamma correction\n","    gamma_corrected = np.power(img / 255.0, gamma) * 255.0\n","    gamma_corrected = np.uint8(gamma_corrected)\n","    return gamma_corrected\n","\n","def process_images(input_dir, output_dir):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for file_name in os.listdir(input_dir):\n","        input_image_path = os.path.join(input_dir, file_name)\n","        output_image_path = os.path.join(output_dir, file_name)\n","\n","        if not os.path.isfile(input_image_path):\n","            print(f\"Skipping non-file: {input_image_path}\")\n","            continue\n","\n","        try:\n","            # Read the image\n","            img = cv2.imread(input_image_path)\n","\n","            if img is None:\n","                print(f\"Failed to load image: {input_image_path}\")\n","                continue\n","\n","            # Apply CLAHE\n","            img = clahe_function(img)\n","\n","            # Apply gamma correction\n","            img = gamma_correction(img)\n","\n","            # Save the processed image\n","            cv2.imwrite(output_image_path, img)\n","\n","        except Exception as e:\n","            print(f\"Exception processing image {input_image_path}: {e}\")\n","\n","# Base directory where your input images are stored\n","base_input_dir = r\"C:/Mansura/UTI/data/External-Validation/UMID\"\n","# Base directory where you want to save the processed images\n","base_output_dir = r\"C:/Mansura/UTI/data/External-Validation/UTI-UMID\"\n","\n","# Define the sets and their respective paths\n","#sets = ['train', 'val', 'test']\n","sets = ['train']\n","\n","for set_name in sets:\n","    input_dir = os.path.join(base_input_dir, set_name, 'images')\n","    output_dir = os.path.join(base_output_dir, set_name, 'images')\n","    process_images(input_dir, output_dir)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","def clahe_function(img):\n","    # Create CLAHE object\n","    clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(8, 8))\n","\n","    # Convert BGR image to LAB color space\n","    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","    # Split LAB image into channels\n","    lab_planes = list(cv2.split(lab_img))\n","\n","    # Apply CLAHE to the L channel\n","    clahe_img = clahe.apply(lab_planes[0])\n","\n","    # Merge the CLAHE-enhanced L channel with the original A and B channels\n","    lab_planes[0] = clahe_img\n","    updated_lab_img = cv2.merge(lab_planes)\n","\n","    # Convert LAB image back to BGR color space\n","    clahe_img_bgr = cv2.cvtColor(updated_lab_img, cv2.COLOR_LAB2BGR)\n","\n","    return clahe_img_bgr\n","\n","def gamma_correction(img, gamma=1.2):\n","    # Apply gamma correction\n","    gamma_corrected = np.power(img / 255.0, gamma) * 255.0\n","    gamma_corrected = np.uint8(gamma_corrected)\n","    return gamma_corrected\n","\n","def process_images(input_dir, output_dir):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for file_name in os.listdir(input_dir):\n","        input_image_path = os.path.join(input_dir, file_name)\n","        output_image_path = os.path.join(output_dir, file_name)\n","\n","        if not os.path.isfile(input_image_path):\n","            print(f\"Skipping non-file: {input_image_path}\")\n","            continue\n","\n","        try:\n","            # Read the image\n","            img = cv2.imread(input_image_path)\n","\n","            if img is None:\n","                print(f\"Failed to load image: {input_image_path}\")\n","                continue\n","\n","            # Apply CLAHE\n","            img = clahe_function(img)\n","\n","            # Apply gamma correction\n","            img = gamma_correction(img)\n","\n","            # Save the processed image\n","            cv2.imwrite(output_image_path, img)\n","\n","        except Exception as e:\n","            print(f\"Exception processing image {input_image_path}: {e}\")\n","\n","# Base directory where your input images are stored\n","base_input_dir = r\"C:/Mansura/UTI/data/DATA-UTI-LR/Sample-Data\"\n","# Base directory where you want to save the processed images\n","base_output_dir = r\"C:/Mansura/UTI/data/DATA-UTI-LR/CG-Sample-Data\"\n","\n","# Define the sets and their respective paths\n","sets = ['train', 'val', 'test']\n","\n","for set_name in sets:\n","    input_dir = os.path.join(base_input_dir, set_name, 'images')\n","    output_dir = os.path.join(base_output_dir, set_name, 'images')\n","    process_images(input_dir, output_dir)\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","def clahe_function(img, clip_limit=2.5, tile_grid_size=(8, 8)):\n","    # Create CLAHE object\n","    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n","\n","    # Convert BGR image to LAB color space\n","    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","    # Split LAB image into channels\n","    lab_planes = list(cv2.split(lab_img))\n","\n","    # Apply CLAHE to the L channel\n","    clahe_img = clahe.apply(lab_planes[0])\n","\n","    # Merge the CLAHE-enhanced L channel with the original A and B channels\n","    lab_planes[0] = clahe_img\n","    updated_lab_img = cv2.merge(lab_planes)\n","\n","    # Convert LAB image back to BGR color space\n","    clahe_img_bgr = cv2.cvtColor(updated_lab_img, cv2.COLOR_LAB2BGR)\n","\n","    return clahe_img_bgr\n","\n","def gamma_correction(img, gamma=1.2):\n","    # Apply gamma correction\n","    gamma_corrected = np.power(img / 255.0, gamma) * 255.0\n","    gamma_corrected = np.uint8(gamma_corrected)\n","    return gamma_corrected\n","\n","def denoise_image(img):\n","    # Apply denoising\n","    denoised_img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n","    return denoised_img\n","\n","def sharpen_image(img):\n","    # Sharpening kernel\n","    kernel = np.array([[0, -1, 0],\n","                       [-1, 5, -1],\n","                       [0, -1, 0]])\n","    sharpened_img = cv2.filter2D(img, -1, kernel)\n","    return sharpened_img\n","\n","def process_images(input_dir, output_dir, clip_limit=2.5, tile_grid_size=(8, 8), gamma=1.2):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for file_name in os.listdir(input_dir):\n","        input_image_path = os.path.join(input_dir, file_name)\n","        output_image_path = os.path.join(output_dir, file_name)\n","\n","        if not os.path.isfile(input_image_path):\n","            print(f\"Skipping non-file: {input_image_path}\")\n","            continue\n","\n","        try:\n","            # Read the image\n","            img = cv2.imread(input_image_path)\n","\n","            if img is None:\n","                print(f\"Failed to load image: {input_image_path}\")\n","                continue\n","\n","            # Apply CLAHE\n","            img = clahe_function(img, clip_limit=clip_limit, tile_grid_size=tile_grid_size)\n","\n","            # Apply gamma correction\n","            img = gamma_correction(img, gamma=gamma)\n","\n","            # Optionally apply denoising\n","            #img = denoise_image(img)\n","\n","            # Optionally apply sharpening\n","            #img = sharpen_image(img)\n","\n","            # Save the processed image\n","            cv2.imwrite(output_image_path, img)\n","\n","        except Exception as e:\n","            print(f\"Exception processing image {input_image_path}: {e}\")\n","\n","# Base directory where your input images are stored\n","base_input_dir = r\"C:/Mansura/UTI/data/DATA-UTI-LR/Data\"\n","# Base directory where you want to save the processed images\n","base_output_dir = r\"C:/Mansura/UTI/data/DATA-UTI-LR/CG-Data\"\n","\n","# Define the sets and their respective paths\n","sets = ['train', 'val', 'test']\n","\n","# Parameters for CLAHE and Gamma correction\n","clip_limit = 2.5  # Adjust this value as needed\n","tile_grid_size = (8, 8)  # Adjust this value as needed\n","gamma = 1.2  # Adjust this value as needed\n","\n","for set_name in sets:\n","    input_dir = os.path.join(base_input_dir, set_name, 'images')\n","    output_dir = os.path.join(base_output_dir, set_name, 'images')\n","    process_images(input_dir, output_dir, clip_limit=clip_limit, tile_grid_size=tile_grid_size, gamma=gamma)\n","    "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","def clahe_function(img):\n","    # Create CLAHE object\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n","\n","    # Convert BGR image to LAB color space\n","    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","\n","    # Split LAB image into channels\n","    lab_planes = list(cv2.split(lab_img))\n","\n","    # Apply CLAHE to the L channel\n","    clahe_img = clahe.apply(lab_planes[0])\n","\n","    # Merge the CLAHE-enhanced L channel with the original A and B channels\n","    lab_planes[0] = clahe_img\n","    updated_lab_img = cv2.merge(lab_planes)\n","\n","    # Convert LAB image back to BGR color space\n","    clahe_img_bgr = cv2.cvtColor(updated_lab_img, cv2.COLOR_LAB2BGR)\n","\n","    return clahe_img_bgr\n","\n","def gamma_correction(img, gamma_bg=1.5, gamma_obj=0.7):\n","    # Create a grayscale image to identify the background and objects\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    \n","    # Threshold the image to create a mask\n","    _, mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n","    \n","    # Normalize the mask to [0, 1]\n","    mask = mask / 255.0\n","    \n","    # Apply gamma correction for the background\n","    img_bg = np.power(img / 255.0, gamma_bg) * 255.0\n","    \n","    # Apply gamma correction for the objects\n","    img_obj = np.power(img / 255.0, gamma_obj) * 255.0\n","    \n","    # Combine the background and object images using the mask\n","    gamma_corrected = img_bg * (1 - mask[..., np.newaxis]) + img_obj * mask[..., np.newaxis]\n","    gamma_corrected = np.uint8(gamma_corrected)\n","    \n","    return gamma_corrected\n","\n","def process_images(input_dir, output_dir):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for file_name in os.listdir(input_dir):\n","        input_image_path = os.path.join(input_dir, file_name)\n","        output_image_path = os.path.join(output_dir, file_name)\n","\n","        if not os.path.isfile(input_image_path):\n","            print(f\"Skipping non-file: {input_image_path}\")\n","            continue\n","\n","        try:\n","            # Read the image\n","            img = cv2.imread(input_image_path)\n","\n","            if img is None:\n","                print(f\"Failed to load image: {input_image_path}\")\n","                continue\n","\n","            # Apply CLAHE\n","            img = clahe_function(img)\n","\n","            # Apply gamma correction\n","            img = gamma_correction(img)\n","\n","            # Save the processed image\n","            cv2.imwrite(output_image_path, img)\n","\n","        except Exception as e:\n","            print(f\"Exception processing image {input_image_path}: {e}\")\n","\n","# Base directory where your input images are stored\n","base_input_dir = r\"C:/Mansura/UTI/data/External-Validation/UMID\"\n","# Base directory where you want to save the processed images\n","base_output_dir = r\"C:/Mansura/UTI/data/External-Validation/UTI-UMID9\"\n","\n","# Define the sets and their respective paths\n","sets = ['train']\n","\n","for set_name in sets:\n","    input_dir = os.path.join(base_input_dir, set_name, 'images')\n","    output_dir = os.path.join(base_output_dir, set_name, 'images')\n","    process_images(input_dir, output_dir)\n"]},{"cell_type":"markdown","metadata":{},"source":["Histogram Equalization RGB"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","\n","def apply_histogram_equalization(input_folder, output_folder):\n","    # Create output folder if it doesn't exist\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    # List all files in the input folder\n","    image_files = os.listdir(input_folder)\n","    \n","    for filename in image_files:\n","        # Read the image\n","        image_path = os.path.join(input_folder, filename)\n","        image = cv2.imread(image_path)\n","        \n","        # Check if the file is an image\n","        if image is not None:\n","            # Split the image into RGB channels\n","            b, g, r = cv2.split(image)\n","            \n","            # Apply histogram equalization to each channel\n","            b_eq = cv2.equalizeHist(b)\n","            g_eq = cv2.equalizeHist(g)\n","            r_eq = cv2.equalizeHist(r)\n","            \n","            # Merge the equalized channels\n","            equalized_image = cv2.merge((b_eq, g_eq, r_eq))\n","            \n","            # Save the processed image\n","            output_path = os.path.join(output_folder, filename)\n","            cv2.imwrite(output_path, equalized_image)\n","\n","            #print(f\"Processed: {filename}\")\n","\n","# Specify input and output folders\n","input_folder = \"C:/Mansura/UTI/data/DATA-UTI-LR/Sample-Data/val/images\"\n","output_folder = \"C:/Mansura/UTI/data/DATA-UTI-LR/HE-Sample-Data/val/images\"\n","\n","# Apply histogram equalization to images in the input folder and save them to the output folder\n","apply_histogram_equalization(input_folder, output_folder)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM6tM1H1sQu49UBCigZ5cfN","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
