{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7047,
     "status": "ok",
     "timestamp": 1713436561429,
     "user": {
      "displayName": "Mohammad Chowdhury",
      "userId": "00677925176328149573"
     },
     "user_tz": -360
    },
    "id": "DoZMQGtczDMc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import json\n",
    "import yaml\n",
    "import locale\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 66286,
     "status": "ok",
     "timestamp": 1713436654503,
     "user": {
      "displayName": "Mohammad Chowdhury",
      "userId": "00677925176328149573"
     },
     "user_tz": -360
    },
    "id": "Z-BJpbwspc82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\n"
     ]
    }
   ],
   "source": [
    "# Download the git repository\n",
    "\n",
    "#!git clone https://github.com/WongKinYiu/yolov9\n",
    "%cd yolov9\n",
    "#!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1713437812926,
     "user": {
      "displayName": "Mohammad Chowdhury",
      "userId": "00677925176328149573"
     },
     "user_tz": -360
    },
    "id": "jvjod8fGp9my"
   },
   "outputs": [],
   "source": [
    "# @title Model training config\n",
    "dataset_path = \"C:/Mansura/UTI-Revision2/ExternalValidation/DATA-UTI-LR/Data\"           # @param {type:\"string\"}\n",
    "experiment_name = \"training.1\"              # @param {type:\"string\"}\n",
    "model_name = \"yolov9-e\"  # @param [\"yolov9-c\", \"yolov9-e\"]\n",
    "result_dir = \"C:/Mansura/UTI-Revision2/ExternalValidation/YOLOv9e\" # @param {type:\"string\"}\n",
    "num_epochs = 100        # @param {type:\"integer\"}\n",
    "epoch_patience = 100     # @param{type: \"integer\"}\n",
    "optimizer = \"SGD\"       # @param [\"SGD\", \"Adam\", \"AdamW\", \"LION\"]\n",
    "image_size = 640        # @param{type: \"integer\"}]\n",
    "#learning_rate = 0.01    # @param {type: \"number\"}\n",
    "batch_size = 8         # @param {type: \"integer\"}\n",
    "conf_threshold = 0.001  # @param {type: \"number\"}\n",
    "iou_threshold = 0.5     # @param {type: \"number\"}\n",
    "pretrained = True       # @param {type:\"boolean\"}\n",
    "\n",
    "weight_name = f\"{model_name}.pt\"\n",
    "cfg_name = f\"models/detect/{model_name}.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1713437085548,
     "user": {
      "displayName": "Mohammad Chowdhury",
      "userId": "00677925176328149573"
     },
     "user_tz": -360
    },
    "id": "JYtVTiYaqpGC"
   },
   "outputs": [],
   "source": [
    "# Setup dataset configuration\n",
    "\n",
    "data_config = {\n",
    "    \"path\": dataset_path,\n",
    "    \"train\": \"train\",       # training data folder name\n",
    "    \"val\": \"val\",           # validation data folder name\n",
    "    \"test\": \"test\",         # testing data folder name\n",
    "\n",
    "    # label to class name mappings\n",
    "    \"names\": {\n",
    "        0: \"epith\",\n",
    "        1: \"rbc/wbc\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    yaml.dump(data_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15887785,
     "status": "ok",
     "timestamp": 1713453707114,
     "user": {
      "displayName": "Mohammad Chowdhury",
      "userId": "00677925176328149573"
     },
     "user_tz": -360
    },
    "id": "fLKhEcq0wBvt",
    "outputId": "b1e25ded-988f-481e-96f2-f730d7d5ede5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=yolov9-e.pt, cfg=models/detect/yolov9-e.yaml, data=data.yaml, hyp=hyp.scratch-high.yaml, epochs=100, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=C:/Mansura/UTI-Revision2/ExternalValidation/YOLOv9e, name=training.1, exist_ok=True, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLO  v0.1-104-g5b1ea9a Python-3.11.5 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO  in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Mansura\\UTI-Revision2\\ExternalValidation\\YOLOv9e', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1         0  models.common.Silence                   []                            \n",
      "  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n",
      "  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      "  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n",
      "  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n",
      "  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n",
      "  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n",
      " 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n",
      " 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n",
      " 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n",
      " 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n",
      " 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n",
      " 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      " 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n",
      " 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n",
      " 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n",
      " 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n",
      " 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n",
      " 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n",
      " 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n",
      " 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n",
      " 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n",
      " 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n",
      " 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n",
      " 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n",
      " 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n",
      " 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n",
      " 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n",
      " 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n",
      " 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n",
      " 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n",
      " 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n",
      " 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n",
      " 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n",
      " 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n",
      " 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n",
      " 49[35, 32, 29, 42, 45, 48]  1  10984364  models.yolo.DualDDetect                 [2, [256, 512, 512, 256, 512, 512]]\n",
      "yolov9-e summary: 1475 layers, 69409388 parameters, 69409356 gradients, 244.9 GFLOPs\n",
      "\n",
      "Transferred 2160/2172 items from yolov9-e.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.0005), 373 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\train\\labels... 4256 images, 1275 backgrounds, 0 corrupt: 100%|██████████| 4256/4256 00:06\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  Cache directory C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\train is not writeable: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Mansura\\\\UTI-Revision2\\\\ExternalValidation\\\\DATA-UTI-LR\\\\Data\\\\train\\\\labels.cache.npy' -> 'C:\\\\Mansura\\\\UTI-Revision2\\\\ExternalValidation\\\\DATA-UTI-LR\\\\Data\\\\train\\\\labels.cache'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\val\\labels... 268 images, 89 backgrounds, 0 corrupt: 100%|██████████| 268/268 00:06\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  Cache directory C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\val is not writeable: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Mansura\\\\UTI-Revision2\\\\ExternalValidation\\\\DATA-UTI-LR\\\\Data\\\\val\\\\labels.cache.npy' -> 'C:\\\\Mansura\\\\UTI-Revision2\\\\ExternalValidation\\\\DATA-UTI-LR\\\\Data\\\\val\\\\labels.cache'\n",
      "Plotting labels to C:\\Mansura\\UTI-Revision2\\ExternalValidation\\YOLOv9e\\training.1\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Mansura\\UTI-Revision2\\ExternalValidation\\YOLOv9e\\training.1\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       0/99        12G      2.416      5.106       1.95         98        640:   0%|          | 0/532 00:02Exception in thread Thread-15 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "WARNING  TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
      "       0/99      12.7G      2.716      5.491      1.778        139        640:   0%|          | 2/532 00:05Exception in thread Thread-16 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "       0/99      12.7G       2.75      5.631      1.735        118        640:   1%|          | 3/532 00:06Exception in thread Thread-17 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "       0/99      23.4G       1.91      1.944      1.405         46        640: 100%|██████████| 532/532 03:30\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.709      0.738      0.733      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/99      23.4G      1.876      1.367      1.377         14        640: 100%|██████████| 532/532 03:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.664      0.645      0.691      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/99      27.8G      1.944      1.472      1.413         86        640: 100%|██████████| 532/532 03:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.531      0.443      0.481      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/99      27.8G      2.005      1.519      1.433         22        640: 100%|██████████| 532/532 03:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.519      0.474      0.462      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/99      27.8G       1.99      1.455      1.423         46        640: 100%|██████████| 532/532 03:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.756      0.735      0.808      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/99      27.8G      1.964      1.382      1.422         62        640: 100%|██████████| 532/532 03:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.387      0.382      0.365      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/99      27.8G      1.924      1.341      1.403        106        640: 100%|██████████| 532/532 03:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.783      0.648      0.757      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/99      27.8G      1.921      1.286        1.4        185        640: 100%|██████████| 532/532 03:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313       0.44      0.294      0.317      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/99      27.8G      1.871      1.243      1.384        107        640: 100%|██████████| 532/532 03:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313       0.81      0.852      0.892      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/99      27.8G      1.848      1.197      1.367         90        640: 100%|██████████| 532/532 03:12\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.799      0.803      0.867      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/99      27.8G       1.85      1.197      1.375         68        640: 100%|██████████| 532/532 03:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.849      0.817      0.882      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/99      27.8G      1.828      1.142      1.357         75        640: 100%|██████████| 532/532 03:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.841      0.784      0.877      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/99      27.8G      1.822      1.143      1.362         85        640: 100%|██████████| 532/532 03:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.839      0.864      0.906      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/99      27.8G      1.823      1.134      1.374        103        640: 100%|██████████| 532/532 03:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.508      0.402      0.463      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/99      27.8G      1.815      1.114      1.365         40        640: 100%|██████████| 532/532 03:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.824      0.847      0.902      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/99      27.8G      1.803      1.108       1.36         67        640: 100%|██████████| 532/532 03:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.822      0.884      0.909      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/99      27.8G      1.779       1.08      1.355         47        640: 100%|██████████| 532/532 03:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313       0.83      0.851       0.91      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/99      27.8G      1.782      1.073       1.35        136        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313       0.87      0.893      0.931       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/99      27.8G      1.788      1.087      1.362         69        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.857      0.864      0.918      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/99      27.8G      1.773      1.058       1.35         44        640: 100%|██████████| 532/532 03:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.858      0.834      0.909       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/99      27.8G      1.765      1.059      1.343        139        640: 100%|██████████| 532/532 03:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.849      0.874      0.915      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/99      27.8G      1.771      1.039      1.337         41        640: 100%|██████████| 532/532 03:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313       0.87      0.884      0.929       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/99      27.8G      1.766      1.051      1.345         80        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.878      0.858      0.928      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/99      27.8G      1.747       1.03       1.34         58        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.859      0.894      0.933       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/99      27.8G       1.74      1.014      1.322         28        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313       0.85      0.893      0.925      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/99      27.8G       1.76      1.025      1.345        131        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.847      0.883      0.923      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/99      27.8G      1.717     0.9944      1.325         33        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.865       0.88      0.937       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/99      27.8G      1.721     0.9999      1.328        146        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313       0.85      0.902      0.933      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/99      27.8G      1.718     0.9984      1.337        123        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.876      0.867      0.935      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/99      27.8G      1.726     0.9982      1.338         85        640: 100%|██████████| 532/532 03:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.859      0.915      0.937      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/99      27.8G      1.716     0.9865      1.324         28        640: 100%|██████████| 532/532 03:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 17/17 00:04\n",
      "                   all        268       1313      0.851      0.909      0.925      0.591\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "%run train_dual.py \\\n",
    "--batch-size {batch_size} \\\n",
    "--epochs {num_epochs} \\\n",
    "--img {image_size} \\\n",
    "--device 0 \\\n",
    "--min-items 0 \\\n",
    "--data data.yaml \\\n",
    "--weights {model_name}.pt \\\n",
    "--cfg models/detect/{model_name}.yaml \\\n",
    "--hyp hyp.scratch-high.yaml \\\n",
    "--optimizer {optimizer} \\\n",
    "--project {result_dir} \\\n",
    "--name {experiment_name} \\\n",
    "--patience {epoch_patience} \\\n",
    "--exist-ok \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49132,
     "status": "ok",
     "timestamp": 1713453875898,
     "user": {
      "displayName": "Mohammad Chowdhury",
      "userId": "00677925176328149573"
     },
     "user_tz": -360
    },
    "id": "EAOws3ajznB5",
    "outputId": "41ab29bd-73b0-4233-b09d-0e1a9f17488f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval_dual: \u001b[0mdata=data.yaml, weights=['C:/Mansura/UTI-Revision2/ExternalValidation/YOLOv9e/training.1/weights/best.pt'], batch_size=8, imgsz=640, conf_thres=0.01, iou_thres=0.5, max_det=300, task=test, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=C:/Mansura/UTI-Revision2/ExternalValidation/YOLOv9e, name=testing.1, exist_ok=True, half=False, dnn=False, min_items=0\n",
      "WARNING  confidence threshold 0.01 > 0.001 produces invalid results\n",
      "YOLO  v0.1-104-g5b1ea9a Python-3.11.5 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\n",
      "Fusing layers... \n",
      "yolov9-e summary: 839 layers, 68549356 parameters, 0 gradients, 240.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels...:   0%|          | 0/852 00:00\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 1 images, 0 backgrounds, 0 corrupt:   0%|          | 1/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 17 images, 0 backgrounds, 0 corrupt:   2%|▏         | 17/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 124 images, 18 backgrounds, 0 corrupt:  15%|█▍        | 124/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 252 images, 80 backgrounds, 0 corrupt:  30%|██▉       | 252/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 372 images, 116 backgrounds, 0 corrupt:  44%|████▎     | 372/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 482 images, 136 backgrounds, 0 corrupt:  57%|█████▋    | 482/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 616 images, 212 backgrounds, 0 corrupt:  72%|███████▏  | 616/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 729 images, 233 backgrounds, 0 corrupt:  86%|████████▌ | 729/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test\\labels... 852 images, 280 backgrounds, 0 corrupt: 100%|██████████| 852/852 00:04\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mWARNING  Cache directory C:\\Mansura\\UTI-Revision2\\ExternalValidation\\DATA-UTI-LR\\Data\\test is not writeable: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Mansura\\\\UTI-Revision2\\\\ExternalValidation\\\\DATA-UTI-LR\\\\Data\\\\test\\\\labels.cache.npy' -> 'C:\\\\Mansura\\\\UTI-Revision2\\\\ExternalValidation\\\\DATA-UTI-LR\\\\Data\\\\test\\\\labels.cache'\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/107 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   1%|          | 1/107 00:00Exception in thread Thread-6 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-7 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   2%|▏         | 2/107 00:00Exception in thread Thread-9 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   3%|▎         | 3/107 00:00Exception in thread Thread-10 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-11 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"c:\\Mansura\\UTI-Revision2\\ExternalValidation\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   4%|▎         | 4/107 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5%|▍         | 5/107 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   6%|▌         | 6/107 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   7%|▋         | 7/107 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   7%|▋         | 8/107 00:01\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|▊         | 9/107 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   9%|▉         | 10/107 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  10%|█         | 11/107 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  11%|█         | 12/107 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  12%|█▏        | 13/107 00:02\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  13%|█▎        | 14/107 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  14%|█▍        | 15/107 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  15%|█▍        | 16/107 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  16%|█▌        | 17/107 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|█▋        | 18/107 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  18%|█▊        | 19/107 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  19%|█▊        | 20/107 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  20%|█▉        | 21/107 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  21%|██        | 22/107 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  21%|██▏       | 23/107 00:04\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  22%|██▏       | 24/107 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  23%|██▎       | 25/107 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  24%|██▍       | 26/107 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 27/107 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  26%|██▌       | 28/107 00:05\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  27%|██▋       | 29/107 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  28%|██▊       | 30/107 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  29%|██▉       | 31/107 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  30%|██▉       | 32/107 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  31%|███       | 33/107 00:06\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  32%|███▏      | 34/107 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|███▎      | 35/107 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  34%|███▎      | 36/107 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  35%|███▍      | 37/107 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  36%|███▌      | 38/107 00:07\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  36%|███▋      | 39/107 00:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  37%|███▋      | 40/107 00:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  38%|███▊      | 41/107 00:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  39%|███▉      | 42/107 00:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  40%|████      | 43/107 00:08\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  41%|████      | 44/107 00:09\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|████▏     | 45/107 00:09\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  43%|████▎     | 46/107 00:09\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  44%|████▍     | 47/107 00:09\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  45%|████▍     | 48/107 00:09\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  46%|████▌     | 49/107 00:10\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  47%|████▋     | 50/107 00:10\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  48%|████▊     | 51/107 00:10\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  49%|████▊     | 52/107 00:10\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|████▉     | 53/107 00:10\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 54/107 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  51%|█████▏    | 55/107 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  52%|█████▏    | 56/107 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  53%|█████▎    | 57/107 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  54%|█████▍    | 58/107 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  55%|█████▌    | 59/107 00:11\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  56%|█████▌    | 60/107 00:12\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  57%|█████▋    | 61/107 00:12\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|█████▊    | 62/107 00:12\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  59%|█████▉    | 63/107 00:12\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  60%|█████▉    | 64/107 00:12\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  61%|██████    | 65/107 00:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  62%|██████▏   | 66/107 00:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  63%|██████▎   | 67/107 00:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  64%|██████▎   | 68/107 00:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  64%|██████▍   | 69/107 00:13\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  65%|██████▌   | 70/107 00:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  66%|██████▋   | 71/107 00:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|██████▋   | 72/107 00:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  68%|██████▊   | 73/107 00:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  69%|██████▉   | 74/107 00:14\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  70%|███████   | 75/107 00:15\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  71%|███████   | 76/107 00:15\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  72%|███████▏  | 77/107 00:15\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  73%|███████▎  | 78/107 00:15\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  74%|███████▍  | 79/107 00:15\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▍  | 80/107 00:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  76%|███████▌  | 81/107 00:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  77%|███████▋  | 82/107 00:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  78%|███████▊  | 83/107 00:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  79%|███████▊  | 84/107 00:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  79%|███████▉  | 85/107 00:16\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  80%|████████  | 86/107 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  81%|████████▏ | 87/107 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  82%|████████▏ | 88/107 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|████████▎ | 89/107 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  84%|████████▍ | 90/107 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  85%|████████▌ | 91/107 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  86%|████████▌ | 92/107 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  87%|████████▋ | 93/107 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  88%|████████▊ | 94/107 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  89%|████████▉ | 95/107 00:19\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  90%|████████▉ | 96/107 00:19\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  91%|█████████ | 97/107 00:19\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|█████████▏| 98/107 00:19\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  93%|█████████▎| 99/107 00:20\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  93%|█████████▎| 100/107 00:20\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  94%|█████████▍| 101/107 00:20\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  95%|█████████▌| 102/107 00:20\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  96%|█████████▋| 103/107 00:20\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  97%|█████████▋| 104/107 00:21\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  98%|█████████▊| 105/107 00:21\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  99%|█████████▉| 106/107 00:21\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 107/107 00:21\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 107/107 00:21\n",
      "                   all        852       4853      0.871      0.882       0.92       0.59\n",
      "                 epith        852       1049      0.807      0.872      0.903      0.597\n",
      "               rbc/wbc        852       3804      0.934      0.891      0.938      0.583\n",
      "Speed: 0.1ms pre-process, 20.3ms inference, 0.6ms NMS per image at shape (8, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Mansura\\UTI-Revision2\\ExternalValidation\\YOLOv9e\\testing.1\u001b[0m\n",
      "763 labels saved to C:\\Mansura\\UTI-Revision2\\ExternalValidation\\YOLOv9e\\testing.1\\labels\n"
     ]
    }
   ],
   "source": [
    "# Test and generate predictions\n",
    "\n",
    "!python val_dual.py --weights \"C:/Mansura/UTI-Revision2/ExternalValidation/YOLOv9e/training.1/weights/best.pt\" \\\n",
    "--data data.yaml \\\n",
    "--save-txt \\\n",
    "--save-conf \\\n",
    "--imgsz {image_size} \\\n",
    "--batch {batch_size} \\\n",
    "--conf 0.01 \\\n",
    "--iou {iou_threshold} \\\n",
    "--device 0 \\\n",
    "--project {result_dir} \\\n",
    "--name {\"testing.1\"} \\\n",
    "--task test \\\n",
    "--exist-ok\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM6tM1H1sQu49UBCigZ5cfN",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
